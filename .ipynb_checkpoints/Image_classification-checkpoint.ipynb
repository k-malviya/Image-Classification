{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data_classify\"\n",
    "TRAIN_PATH = '%s/train/' % (DATA_PATH)\n",
    "VALID_PATH =  '%s/valid/' % (DATA_PATH)\n",
    "TEST_PATH = '%s/test/' % (DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "image_width = 150 #specify the size\n",
    "image_height = 150\n",
    "image_size = (image_width, image_height)\n",
    "\n",
    "batch_size = 10 #do not exceed the memory limit ,10 images at time\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255) #convert float by float number\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        TRAIN_PATH,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        VALID_PATH,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datagen= ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_generator = datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        TRAIN_PATH,\n",
    "    shuffle=True, #give the images in order\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "x, y = data_generator.next()\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, (img, label) in enumerate(zip(x, y)):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    if label == 1:\n",
    "        plt.title('Non Cancerous')\n",
    "    else:\n",
    "        plt.title('Cancerous')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "lenet_model = Sequential()\n",
    "lenet_model.add(Conv2D(6, (5, 5), activation='relu',name='conv1', # 6 is o/p channel\n",
    "                        input_shape=(150, 150, 3))) # 6no of filters,5 is no of layers,# 3 is i/p channel\n",
    "lenet_model.add(MaxPooling2D((2, 2), name='pool1'))\n",
    "lenet_model.add(Conv2D(16, (5, 5), activation='relu', name='conv2'))\n",
    "lenet_model.add(MaxPooling2D((2, 2), name='pool2')) # takes the max of the matrix\n",
    "lenet_model.add(Flatten(name='flatten'))\n",
    "lenet_model.add(Dense(120, activation='relu', name='fc1'))\n",
    "lenet_model.add(Dense(84, activation='relu', name='fc2'))\n",
    "lenet_model.add(Dense(1, activation='sigmoid', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(lenet_model, to_file='cats_and_dogs_lenet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(lenet_model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ended our network with a single sigmoid unit, we will use binary crossentropy as our loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "lenet_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "best_model = ModelCheckpoint(\"./lenet/cats_and_dogs_lenet.h5\", monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "history = lenet_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=30, #300/10  10 is the batch size\n",
    "        validation_steps=5, #50/10\n",
    "        epochs=10, #iterate images 10 times\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[best_model, TensorBoard(log_dir='./lenet/logs')]) #callback to save the model and check model is improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using data augmentation\n",
    "Data augmentation takes the approach of generating more training data from existing training samples, by \"augmenting\" the samples via a number of random transformations that yield believable-looking images.\n",
    "The goal is that at training time, our model would never see the exact same picture twice. This helps the model get exposed to more aspects of the data and generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "fnames = [os.path.join(TEST_PATH, fname) for fname in os.listdir(TEST_PATH)]\n",
    "\n",
    "# We pick one image to \"augment\"\n",
    "img_path = fnames[5]\n",
    "\n",
    "# Read the image and resize it\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "# Convert it to a Numpy array with shape (150, 150, 3)\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Reshape it to (1, 150, 150, 3) because the flow method requires the input array to be of rank 4\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# The .flow() command below generates batches of randomly transformed images.\n",
    "# It will loop indefinitely, so we need to `break` the loop at some point!\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = 150 \n",
    "image_height = 150\n",
    "image_size = (image_width, image_height)\n",
    "batch_size = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1.0/255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_PATH,  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255) # we only need to rescale images for validation\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        VALID_PATH,  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we train a new network using this data augmentation configuration, our network will never see twice the same input. However, the inputs that it sees are still heavily intercorrelated, since they come from a small number of original images -- we cannot produce new information, we can only remix existing information.\n",
    "As such, this might not be quite enough to completely get rid of overfitting. To further fight overfitting, we will also add a Dropout layer with 50% probability to our model, right before the densely-connected classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "lenet_model = Sequential()\n",
    "lenet_model.add(Conv2D(6, (5, 5), activation='relu',name='conv1',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "lenet_model.add(MaxPooling2D((2, 2), name='pool1'))\n",
    "lenet_model.add(Conv2D(16, (5, 5), activation='relu', name='conv2'))\n",
    "lenet_model.add(MaxPooling2D((2, 2), name='pool2'))\n",
    "lenet_model.add(Flatten(name='flatten'))\n",
    "# The new dropout layer\n",
    "lenet_model.add(Dropout(0.5))\n",
    "lenet_model.add(Dense(120, activation='relu', name='fc1'))\n",
    "lenet_model.add(Dense(84, activation='relu', name='fc2'))\n",
    "lenet_model.add(Dense(1, activation='sigmoid', name='predictions'))\n",
    "\n",
    "lenet_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our network using data augmentation and dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "best_model = ModelCheckpoint(\"./lenet/cats_and_dogs_lenet.h5\", monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "history = lenet_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=30, #300/10 10 is the batch size\n",
    "        validation_steps=5, #51/10\n",
    "        epochs=10, #try increasing epcoh to see if validation improves\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[best_model, TensorBoard(log_dir='./lenet/logs')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss and accuracy of the model over the training and validation data during training.\n",
    "You can see our training accuracy climbed slower than the previous network and the training/valid accuracy correlate well this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a pre-trained convnet - Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(conv_base)\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(256, activation='relu'))\n",
    "vgg_model.add(Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we compile and train our model, a very important thing to do is to freeze the convolutional base. \"Freezing\" a layer or set of layers means preventing their weights from getting updated during training. If we don't do this, then the representations that were previously learned by the convolutional base would get modified during training.\n",
    "Since the Dense layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.\n",
    "In Keras, freezing a network is done by setting its trainable attribute to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerun the data generator before we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1.0/255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_PATH,  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255) # we only need to scale the input for validation set\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        VALID_PATH,  # this is the target directory\n",
    "        target_size=image_size,  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model will go through all conv base layer during the training process, each epoch is taking longer than our baseline lenet model. We will lower the number of epoch to 2 for the sake of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "best_model = ModelCheckpoint(\"./vgg16/cats_and_dogs_vgg16.h5\", monitor='val_loss', verbose=0, save_best_only=True)\n",
    "\n",
    "\n",
    "history = vgg_model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=30, #300/10 10 is the batch size\n",
    "            validation_steps=5, #50/10\n",
    "            epochs=10, # Change this to a bigger number if you want to train for more epochs\n",
    "            validation_data=validation_generator,\n",
    "            callbacks=[best_model, TensorBoard(log_dir='./vgg16/logs')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the loss and accuracy of the model over the training and validation data during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### import os\n",
    "test_iamges  = os.listdir(TEST_PATH)\n",
    "\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = load_img(img_path, target_size=image_size)\n",
    "    img_tensor = img_to_array(img) \n",
    "    # change it to shape [1, 150, 150, 3]\n",
    "    #img_tensor =[1, 150, 150, 3]\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "    img_tensor /= 255.\n",
    "    return img_tensor\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "for index, image in enumerate(test_iamges):\n",
    "    img = preprocess_image(TEST_PATH + image)\n",
    "    \n",
    "    prediction = vgg_model.predict(img)[0]\n",
    "    \n",
    "    plt.subplot(5,7,index+1)\n",
    "    if prediction < 0.3:\n",
    "        plt.title('Cancerous %.2f%%' % (100 - prediction*100))\n",
    "    else:\n",
    "        plt.title('NonCancerous %.2f%%' % (prediction*100))\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.imshow(img[0])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
